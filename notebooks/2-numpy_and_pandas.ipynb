{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and pandas\n",
    "## General\n",
    "### NumPy\n",
    "NumPy is used for performing numerical computations on arrays and matrices, such as mean, median, percentiles and linear algebra computations. Simply install numpy with pip `pip3 install numpy`. \n",
    "\n",
    "### Pandas\n",
    "Pandas is used for handling tabular datasets that usually combine different types of data columns (integer, float, nominals, etc). Pandas requires NumPy. To install: `pip3 install pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zeros'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# zeros and ones. array shape\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'zeros'"
     ]
    }
   ],
   "source": [
    "# zeros and ones. array shape\n",
    "import numpy as np\n",
    "a = np.zeros((2, 4))\n",
    "b = np.ones((2, 4))\n",
    "print(f\"a:\\n{a}\")\n",
    "print(f\"b:\\n{b}\")\n",
    "print(f\"a+b:\\n{a+b}\")\n",
    "print(f\"a-2b:\\n{a-2*b}\")\n",
    "print(f\"shape:\\n{a.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating arrays from lists and array types\n",
    "import numpy as np\n",
    "a = np.array([1, 2, 5])\n",
    "b = np.array([2.0, 10, -1])\n",
    "print(f\"a+b{a + b}\")\n",
    "print(a.dtype)\n",
    "print(b.dtype)\n",
    "print((a+b).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change the type of a numpy array use astype():\n",
    "import numpy as np\n",
    "b = np.array([2.1, 10, -5])\n",
    "b_reduced = b.astype('uint8')\n",
    "print(b.dtype)\n",
    "print(b_reduced.dtype)\n",
    "print(b_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[200, 100], [100, 200]]).astype('uint8')\n",
    "y = np.array([[255, 100], [100, 255]]).astype('uint8')\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y)\n",
    "print(\"(Result is overfloated!)\")\n",
    "print(\"\\n Results with type conversion:\")\n",
    "print(x.astype('int32') + y.astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.arange. basic operations\n",
    "import numpy as np\n",
    "a = np.arange(0, 20, 5)\n",
    "b = np.arange(0, 20, 5) - 10\n",
    "print(f\"a:{a}\")\n",
    "print(f\"a-10:{a-10}\")\n",
    "print(f\"a^2:{a ** 2}\")\n",
    "print(f\"a-b:{a-b}\")\n",
    "print(f\"cos(b * pi / 20):{np.cos(b * np.pi / 20.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element-wise product matrix product\n",
    "import numpy as np\n",
    "A = np.array([[0, 2], [1, 1]])\n",
    "B = np.array([[-1, 1], [1, 1]])\n",
    "print(f\"A .* B =\\n {A * B}\")     # element-wise\n",
    "print(f\"A * B =\\n {A.dot(B)}\")  # matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping arrays\n",
    "import numpy as np\n",
    "x = np.arange(10)\n",
    "print(x)\n",
    "print(x.reshape(2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy statistics\n",
    "The following example reads the temperatures from NYC in the last 150 years on the same day (9th April). The csv file contains 3 rows, namely date, max day temp and min day temp. Date is saved in a list and the two temperatures in numpy arrays. The following code extracts some basic statistics including, mean vale, median value, max, min and  10 and 90 percentiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "years = []\n",
    "max_t, min_t = np.array([]), np.array([])\n",
    "# read the csv file of New York min and max temperatures of 9th April for the last 150 years:\n",
    "with open('data_ny_temperatures.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for ir, row in enumerate(reader):\n",
    "        if ir>0:\n",
    "            max_t = np.append(max_t, float(row[1]))\n",
    "            min_t = np.append(min_t, float(row[2]))\n",
    "            years.append(int(row[0].split('-')[0]))\n",
    "\n",
    "print(f\"Average max-day temperature is {max_t.mean():.1f}\")\n",
    "print(f\"Median max-day temperature is {np.median(max_t):.1f}\")\n",
    "print(f\"Average min-day temperature is {min_t.mean():.1f}\")\n",
    "print(f\"Median min-day temperature is {np.median(min_t):.1f}\")\n",
    "\n",
    "print(f\"The maximum max-day temp was {np.max(max_t):.1f} in {years[np.argmax(max_t)]}\")\n",
    "print(f\"The maximum min-day temp was {np.max(min_t):.1f} in {years[np.argmax(min_t)]}\")\n",
    "print(f\"The minimum max-day temp was {np.min(max_t):.1f} in {years[np.argmin(max_t)]}\")\n",
    "print(f\"The minimum max-day temp was {np.min(min_t):.1f} in {years[np.argmin(min_t)]}\")\n",
    "\n",
    "max_t_p_10 = np.percentile(max_t, 10)\n",
    "max_t_p_90 = np.percentile(max_t, 90)\n",
    "years_max_10 = [y for i, y in enumerate(years) if max_t[i] < max_t_p_10]\n",
    "# Note: this is equvalent to the followingL\n",
    "# years_max_10 = []\n",
    "#for i, y in enumerate(years):\n",
    "#    if max_t[i] < max_t_p_10:\n",
    "#        years_max_10.append(y)\n",
    "print(years_max_10)\n",
    "years_max_90 = [y for i, y in enumerate(years) if max_t[i] > max_t_p_90]\n",
    "print(years_max_90)\n",
    "min_t_p_10 = np.percentile(min_t, 10)\n",
    "min_t_p_90 = np.percentile(min_t, 90)\n",
    "years_min_10 = [y for i, y in enumerate(years) if min_t[i] < min_t_p_10]\n",
    "print(years_min_10)\n",
    "years_min_90 = [y for i, y in enumerate(years) if min_t[i] > min_t_p_90]\n",
    "print(years_min_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on speed: if you need to append a large number of elements in a numpy array, it is much faster to append it to a list and then convert the list to numpy array (instead of using the numpy.append() method). And list comprehension is obvioysly even faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "a = np.array([])\n",
    "for i in range(1, 10000):\n",
    "    a = np.append(a, i)\n",
    "t2 = time.time()\n",
    "print(f\"numpy.append(): {1000 * (t2 - t1):.2f} msecs\")\n",
    "\n",
    "t1 = time.time()\n",
    "a = []\n",
    "for i in range(1, 10000):\n",
    "    a.append(i)\n",
    "a = np.array(a)\n",
    "t2 = time.time()\n",
    "print(f\"list append and numpy array conversion: {1000 * (t2 - t1):.2f} msecs\")\n",
    "\n",
    "t1 = time.time()\n",
    "a = [i for i in range(1, 10000)]\n",
    "a = np.array(a)\n",
    "t2 = time.time()\n",
    "print(f\"list comprehension and numpy array conversion: {1000 * (t2 - t1):.2f} msecs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talking about statistics, two of the most important quantities used in random variable statistics (whatever quantity they measure) are mean and standard deviation. We've already seen mean in some examples above. Standard deviation, which measures how close the values of the variable are to their mean value. Below, we are showing how to compute mean and std of a sequence and how to standardize the values of the sequence into having a standard deviation of 1 and mean value equal to 0. This is a very important process, used in machine learning and data science before training models and before predicting. An alternative is the max / min normalization, not shown here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random\n",
    "m, s, n_samples = 10, 5, 1000\n",
    "x = numpy.random.normal(m, s, n_samples)\n",
    "m_est = x.mean()\n",
    "s_est = x.std()\n",
    "\n",
    "print(f\"mean is {m_est:.3f} and std is {s_est:.3f}\")\n",
    "# z = (x - m) / s\n",
    "x_norm = (x - m_est) / s_est\n",
    "print(f\"after standardization mean is {x_norm.mean():.3f} and std is {x_norm.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy slicing and row - column operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2,3], [4,5,6], [7, 8, 9], [10, 11, 12]])\n",
    "print(\"x:\")\n",
    "print(x)\n",
    "print(\"\\nx[1:, :-1]:\")\n",
    "print(x[1:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global and row-wise or column-wise calculations\n",
    "import numpy as np\n",
    "x = np.array([[1,2,3], [4,5,6], [7, 8, 9], [10, 11, 12]])\n",
    "print(f\"global mean {x.mean()}\")\n",
    "print(f\"global min {x.min()}\")\n",
    "print(f\"global max {x.max()}\")\n",
    "print(f\"column-wise mean {x.mean(axis=0)}\")\n",
    "print(f\"row-wise mean {x.mean(axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "Broadcasting in numpy is. a very powerful mechanism that allows numpy operators to work on arrays of different shapes.\n",
    "\n",
    "We saw previously that element-to-element operations are possible in numpy when arrays have the same dimensions. However, operations on arrays that do not share the same shapes is possible in numpy because of broadcasting. Broadcasting can be performed when the shape of each dimension in the arrays are equal or one has the one of its dimensions equal to 1. Below are some broadcasting examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broacasting examples\n",
    "import numpy as np\n",
    "# example 1:\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "print(x + 2)  # scalar and 2D array broadcasting\n",
    "\n",
    "# example 2:\n",
    "x = np.array([[1,2,3], [4,5,6], [7, 8, 9], [10, 11, 12]])\n",
    "y = np.array([1, 2, 3])\n",
    "print(f\"add a {x.shape[0]}x{x.shape[1]} with a {y.shape[0]}x{1} numpy array:\")\n",
    "print(x + y)\n",
    "\n",
    "#example 3:\n",
    "y = np.array([1, 2, 3, 4]).reshape(4,1)\n",
    "print(f\"add a {x.shape[0]}x{x.shape[1]} with a {y.shape[0]}x{1} numpy array:\")\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A normalization example without looping (using numpy broadcasting)\n",
    "# initialize features (columns represent features and rows represent instances)\n",
    "X = np.array([[200,0.1],[220,0.15],[250,0.11],[300,0.15],[320,0.16],[240,0.14]])\n",
    "\n",
    "# get mean / std per feature (per column):\n",
    "m = X.mean(axis=0) \n",
    "s = X.std(axis=0)\n",
    "\n",
    "# normalize (without having to loop through different rows):\n",
    "X_norm = (X - m) / s\n",
    "# now X_norm is normalized with mean = 0 , std = 1:\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "### Pandas data structures\n",
    "Two are the basic types used in pandas: *series* and *dataframes*.\n",
    "Series is a 1D labeled array that holds any data type (integers, strings, floats etc). To define a Series we need its data and its indices. Obviously the index must be of the same length to the data. If index is not defined, then the default value is \\[0, ..., len(data) - 1\\]. \n",
    "\n",
    "#### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series definition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series(np.random.randn(10), index=[f'index{i}' for i in range(10)])\n",
    "print(\"series:\"); print(s)\n",
    "print(\"s.index\"); print(s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one can also initialize series from dict:\n",
    "s = pd.Series({'a': 2.1, 'c': 1.9, 'b': 1, 'd': -1})\n",
    "print(\"series:\"); print(s)\n",
    "print(\"s.index\"); print(s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing in series can be done with both its indices and integers\n",
    "print(s[1], s['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also Series shares functions from numpy arrays:\n",
    "s.mean(), s.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and more functions:\n",
    "np.cos(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing similar to numpy arrays:\n",
    "s[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT, operations are not the same as numpy. E.g. + results in the union of the indices involved\n",
    "# NaN is assigned as the default value for indices that are not in both series \n",
    "a = pd.Series({'a': 2.1, 'b': 1, 'c': -1})\n",
    "b = pd.Series({'a': 1, 'd': 1, 'g': -1, 'c': -1})\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame\n",
    "When your data is tabular with row index and column index, the go-to choice is pandas.DataFrame. DataFrame  is a 2D data structure with columns of potentially different types. Conceptually, DataFrame can be considered as a data table stored in a spreadsheet, a csv, a json file or a database. \n",
    "\n",
    "There are several ways to construct a DataFrame object, below are two of the most frequent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct DataFrame from dict\n",
    "import pandas as pd\n",
    "d = {'name': [\"james\", \"theodore\", \"jane\", \"maria\"], \n",
    "     'score': [4., 3., 2., 5.]}\n",
    "df = pd.DataFrame(d)\n",
    "print(df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct DataFrame from list of dicts\n",
    "# (note that \"sparse\" matrices - aka missing data - are more easily supported using this format)\n",
    "import pandas as pd\n",
    "d = [{'name': 'james', 'score': '4', 'note': 'this is a note'},\n",
    "     {'name': 'theodore', 'score': '3'},\n",
    "     {'name': 'jane', 'score': '2'},\n",
    "     {'name': 'maria', 'score': '5'}]\n",
    "df = pd.DataFrame(d)\n",
    "print(df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets read the CSV file of temperatures again:\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "print(f\"{len(list(df.columns))} columns {list(df.columns)}\")\n",
    "print(f\"{len(df.index)} rows\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT a column:\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a column to numpy array:\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df['maxt'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... or to list\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df['mint'].to_list()[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also INSERT a new column e.g.\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df['meant'] = (df['mint'] + df['maxt']) / 2\n",
    "# or you can insert a fixed (non-array) value (it will be added to ALL rows)\n",
    "df['note'] = 'this is a note'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE a column\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "del df['maxt']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that indexing columns is done like in dicts e.g. df['maxt']. What about indexing rows and assining values to individual cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "print(df.iloc[0]) # index rows\n",
    "# you can also use df.loc iand provide a LABEL instead of an integer\n",
    "# (if the dataframe has been defined with labels in rows, see next examples)\n",
    "\n",
    "# ASSIGN a value to a specific CELL:\n",
    "df.loc[0, 'maxt'] = -10\n",
    "\n",
    "df.iloc[0, df.columns.get_loc(\"maxt\")] = -10\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example\n",
    " * we set the index of the temperatures matrix from default (integers) to the date\n",
    " * we demonstrate how to use the loc method to index when non-integer indices are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df = df.set_index(\"date\")\n",
    "print(df)\n",
    "# you can now use the loc method\n",
    "df.loc[\"2018-04-09\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLICING\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df = df.set_index(\"date\")\n",
    "print(df[::20]) # print every 20 rows\n",
    "print(df[2:4])  # print rows 2 to 3\n",
    "print(df[\"1929-04-09\": \"1944-04-09\"])  # use non-integer indices in slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTION\n",
    "print(df[df['maxt'] > 80]) # select rows with maxt>80\n",
    "print(df[df['maxt'] - df['mint'] < 5]) # select rows with less than 5 difference between maxt and mint\n",
    "print(df[(df['maxt'] > 80) | (df['mint'] < 28)]) # select rows with very high max or very low min temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORTING\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data_ny_temperatures.csv\")\n",
    "df = df.set_index(\"date\")\n",
    "df = df.sort_values(by='mint') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
